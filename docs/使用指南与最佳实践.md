# Go-Agent 使用指南与最佳实践

## 目录

1. [快速开始](#快速开始)
2. [常见使用场景](#常见使用场景)
3. [最佳实践](#最佳实践)
4. [配置指南](#配置指南)
5. [故障排查](#故障排查)
6. [性能调优](#性能调优)
7. [示例代码库](#示例代码库)

---

## 快速开始

### 环境准备

#### 1. 安装依赖

```bash
# 克隆项目
git clone https://github.com/Protocol-Lattice/go-agent.git
cd go-agent

# 下载依赖
go mod download
```

#### 2. 配置环境变量

```bash
# 根据使用的 LLM 提供商配置相应的 API Key
export GOOGLE_API_KEY="your-gemini-api-key"          # Gemini
export ANTHROPIC_API_KEY="your-claude-api-key"       # Claude
export OPENAI_API_KEY="your-openai-api-key"          # OpenAI

# 数据库配置（可选）
export DATABASE_URL="postgres://user:pass@localhost:5432/lattice"
export QDRANT_URL="http://localhost:6333"
export NEO4J_URI="bolt://localhost:7687"
export MONGODB_URI="mongodb://localhost:27017"
```

### 最简示例

```go
package main

import (
    "context"
    "fmt"
    "log"
    
    "github.com/Protocol-Lattice/go-agent"
    "github.com/Protocol-Lattice/go-agent/src/memory"
    "github.com/Protocol-Lattice/go-agent/src/models"
)

func main() {
    ctx := context.Background()
    
    // 1. 创建模型
    model, err := models.NewGeminiLLM(ctx, "gemini-2.5-pro", "")
    if err != nil {
        log.Fatal(err)
    }
    
    // 2. 创建记忆系统
    store := memory.NewInMemoryStore()
    engine := memory.NewEngine(store, memory.DefaultOptions())
    bank := memory.NewMemoryBankWithStore(store, engine)
    sessionMemory := memory.NewSessionMemory(bank, 10)
    
    // 3. 创建智能体
    agent, err := agent.New(agent.Options{
        Model:        model,
        Memory:       sessionMemory,
        SystemPrompt: "You are a helpful assistant.",
        ContextLimit: 8,
    })
    if err != nil {
        log.Fatal(err)
    }
    
    // 4. 进行对话
    response, err := agent.Generate(ctx, "session-1", "Hello, who are you?")
    if err != nil {
        log.Fatal(err)
    }
    
    fmt.Println("Agent:", response)
}
```

### 使用 ADK 的快速示例

```go
package main

import (
    "context"
    "log"
    
    "github.com/Protocol-Lattice/go-agent/src/adk"
    "github.com/Protocol-Lattice/go-agent/src/adk/modules"
    "github.com/Protocol-Lattice/go-agent/src/memory"
    "github.com/Protocol-Lattice/go-agent/src/models"
)

func main() {
    ctx := context.Background()
    
    // 使用 ADK 声明式配置
    kit, err := adk.New(ctx,
        adk.WithDefaultSystemPrompt("You are a helpful assistant."),
        adk.WithModules(
            // 模型模块
            modules.NewModelModule("gemini", func(ctx context.Context) (models.Agent, error) {
                return models.NewGeminiLLM(ctx, "gemini-2.5-pro", "")
            }),
            // 内存模块
            modules.InMemoryMemoryModule(100000, memory.AutoEmbedder(), nil),
        ),
    )
    if err != nil {
        log.Fatal(err)
    }
    
    // 构建智能体
    agent, err := kit.BuildAgent(ctx)
    if err != nil {
        log.Fatal(err)
    }
    
    // 使用智能体
    response, _ := agent.Generate(ctx, "session-1", "Hello!")
    log.Println(response)
}
```
// 使用adk和直接使用agent的区别在于，adk提供了一个模块化的依赖注入容器，可以更方便地管理复杂的依赖关系和配置。直接使用agent需要手动创建和配置每个组件，而adk允许你通过声明式的方式定义模块和依赖，自动处理实例化和注入。这使得代码更简洁、可维护，并且更容易进行测试和扩展。

---

## 常见使用场景

### 场景 1: 简单对话机器人

```go
package main

import (
    "bufio"
    "context"
    "fmt"
    "log"
    "os"
    "strings"
    
    "github.com/Protocol-Lattice/go-agent"
    "github.com/Protocol-Lattice/go-agent/src/memory"
    "github.com/Protocol-Lattice/go-agent/src/models"
)

func main() {
    ctx := context.Background()
    
    // 创建智能体
    model, _ := models.NewGeminiLLM(ctx, "gemini-2.5-pro", "")
    store := memory.NewInMemoryStore()
    engine := memory.NewEngine(store, memory.DefaultOptions())
    bank := memory.NewMemoryBankWithStore(store, engine)
    sessionMemory := memory.NewSessionMemory(bank, 10)
    
    agent, err := agent.New(agent.Options{
        Model:        model,
        Memory:       sessionMemory,
        SystemPrompt: "You are a friendly chatbot. Be helpful and concise.",
    })
    if err != nil {
        log.Fatal(err)
    }
    
    // 交互循环
    scanner := bufio.NewScanner(os.Stdin)
    sessionID := "chat-session"
    
    fmt.Println("Chatbot ready! Type 'exit' to quit.")
    fmt.Println("---")
    
    for {
        fmt.Print("You: ")
        if !scanner.Scan() {
            break
        }
        
        userInput := strings.TrimSpace(scanner.Text())
        if userInput == "" {
            continue
        }
        if userInput == "exit" {
            fmt.Println("Goodbye!")
            break
        }
        
        response, err := agent.Generate(ctx, sessionID, userInput)
        if err != nil {
            log.Printf("Error: %v\n", err)
            continue
        }
        
        fmt.Printf("Bot: %s\n\n", response)
    }
}
```

### 场景 2: 带工具的智能体

```go
package main

import (
    "context"
    "fmt"
    "log"
    "time"
    
    "github.com/Protocol-Lattice/go-agent"
    "github.com/Protocol-Lattice/go-agent/src/memory"
    "github.com/Protocol-Lattice/go-agent/src/models"
)

// 1. 定义一个时间工具
type TimeTool struct{}

func (t *TimeTool) Spec() agent.ToolSpec {
    return agent.ToolSpec{
        Name:        "get_current_time",
        Description: "Returns the current time in a specified timezone",
        InputSchema: map[string]any{
            "type": "object",
            "properties": map[string]any{
                "timezone": map[string]any{
                    "type":        "string",
                    "description": "Timezone name (e.g., 'UTC', 'America/New_York')",
                },
            },
            "required": []string{"timezone"},
        },
    }
}

func (t *TimeTool) Invoke(ctx context.Context, req agent.ToolRequest) (agent.ToolResponse, error) {
    timezone, ok := req.Arguments["timezone"].(string)
    if !ok {
        timezone = "UTC"
    }
    
    loc, err := time.LoadLocation(timezone)
    if err != nil {
        return agent.ToolResponse{}, err
    }
    
    currentTime := time.Now().In(loc).Format(time.RFC1123)
    
    return agent.ToolResponse{
        Content: fmt.Sprintf("Current time in %s: %s", timezone, currentTime),
    }, nil
}

// 2. 定义一个计算器工具
type CalculatorTool struct{}

func (c *CalculatorTool) Spec() agent.ToolSpec {
    return agent.ToolSpec{
        Name:        "calculator",
        Description: "Performs basic arithmetic operations",
        InputSchema: map[string]any{
            "type": "object",
            "properties": map[string]any{
                "operation": map[string]any{
                    "type":        "string",
                    "description": "Operation: add, subtract, multiply, divide",
                    "enum":        []string{"add", "subtract", "multiply", "divide"},
                },
                "a": map[string]any{
                    "type":        "number",
                    "description": "First number",
                },
                "b": map[string]any{
                    "type":        "number",
                    "description": "Second number",
                },
            },
            "required": []string{"operation", "a", "b"},
        },
    }
}

func (c *CalculatorTool) Invoke(ctx context.Context, req agent.ToolRequest) (agent.ToolResponse, error) {
    op, _ := req.Arguments["operation"].(string)
    a, _ := req.Arguments["a"].(float64)
    b, _ := req.Arguments["b"].(float64)
    
    var result float64
    switch op {
    case "add":
        result = a + b
    case "subtract":
        result = a - b
    case "multiply":
        result = a * b
    case "divide":
        if b == 0 {
            return agent.ToolResponse{}, fmt.Errorf("division by zero")
        }
        result = a / b
    default:
        return agent.ToolResponse{}, fmt.Errorf("unknown operation: %s", op)
    }
    
    return agent.ToolResponse{
        Content: fmt.Sprintf("%s(%g, %g) = %g", op, a, b, result),
    }, nil
}

func main() {
    ctx := context.Background()
    
    // 创建带工具的智能体
    model, _ := models.NewGeminiLLM(ctx, "gemini-2.5-pro", "")
    store := memory.NewInMemoryStore()
    engine := memory.NewEngine(store, memory.DefaultOptions())
    bank := memory.NewMemoryBankWithStore(store, engine)
    sessionMemory := memory.NewSessionMemory(bank, 10)
    
    agent, err := agent.New(agent.Options{
        Model:        model,
        Memory:       sessionMemory,
        SystemPrompt: "You are a helpful assistant with access to tools.",
        Tools: []agent.Tool{
            &TimeTool{},
            &CalculatorTool{},
        },
    })
    if err != nil {
        log.Fatal(err)
    }
    
    // 测试工具调用
    response, err := agent.Generate(ctx, "session-1", 
        "What time is it in Tokyo? Also, what is 42 * 17?")
    if err != nil {
        log.Fatal(err)
    }
    
    fmt.Println("Agent:", response)
}
```

### 场景 3: 多智能体协同

```go
package main

import (
    "context"
    "fmt"
    "log"
    
    "github.com/Protocol-Lattice/go-agent"
    "github.com/Protocol-Lattice/go-agent/src/memory"
    "github.com/Protocol-Lattice/go-agent/src/models"
    "github.com/Protocol-Lattice/go-agent/src/subagents"
)

func main() {
    ctx := context.Background()
    
    // 1. 创建子智能体的模型
    researcherModel, _ := models.NewGeminiLLM(ctx, "gemini-2.5-pro", "Research:")
    writerModel, _ := models.NewGeminiLLM(ctx, "gemini-2.5-pro", "Writing:")
    
    // 2. 创建子智能体
    researcher := subagents.NewResearcher(researcherModel)
    
    // 3. 创建主智能体
    mainModel, _ := models.NewGeminiLLM(ctx, "gemini-2.5-pro", "")
    store := memory.NewInMemoryStore()
    engine := memory.NewEngine(store, memory.DefaultOptions())
    bank := memory.NewMemoryBankWithStore(store, engine)
    sessionMemory := memory.NewSessionMemory(bank, 10)
    
    mainAgent, err := agent.New(agent.Options{
        Model:  mainModel,
        Memory: sessionMemory,
        SystemPrompt: `You are a team coordinator. You have access to specialist sub-agents:
- researcher: For research and fact-finding
Delegate tasks appropriately.`,
        SubAgents: []agent.SubAgent{
            researcher,
        },
    })
    if err != nil {
        log.Fatal(err)
    }
    
    // 4. 执行协同任务
    response, err := mainAgent.Generate(ctx, "session-1", 
        "Research the latest developments in quantum computing and summarize key findings.")
    if err != nil {
        log.Fatal(err)
    }
    
    fmt.Println("Response:", response)
}
```

### 场景 4: Agent 状态持久化

```go
package main

import (
    "context"
    "fmt"
    "log"
    "os"
    
    "github.com/Protocol-Lattice/go-agent"
    "github.com/Protocol-Lattice/go-agent/src/memory"
    "github.com/Protocol-Lattice/go-agent/src/models"
)

func main() {
    ctx := context.Background()
    
    // 创建智能体
    model, _ := models.NewGeminiLLM(ctx, "gemini-2.5-pro", "")
    store := memory.NewInMemoryStore()
    engine := memory.NewEngine(store, memory.DefaultOptions())
    bank := memory.NewMemoryBankWithStore(store, engine)
    sessionMemory := memory.NewSessionMemory(bank, 10)
    
    agent1, _ := agent.New(agent.Options{
        Model:        model,
        Memory:       sessionMemory,
        SystemPrompt: "You are a helpful assistant.",
    })
    
    // 进行对话
    _, _ = agent1.Generate(ctx, "session-1", "My favorite color is blue.")
    _, _ = agent1.Generate(ctx, "session-1", "I live in Tokyo.")
    
    // 保存状态
    fmt.Println("Saving agent state...")
    checkpointData, err := agent1.Checkpoint()
    if err != nil {
        log.Fatal(err)
    }
    
    err = os.WriteFile("agent_checkpoint.json", checkpointData, 0644)
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf("Saved %d bytes to agent_checkpoint.json\n", len(checkpointData))
    
    // --- 模拟程序重启 ---
    
    // 创建新的智能体实例
    newStore := memory.NewInMemoryStore()
    newEngine := memory.NewEngine(newStore, memory.DefaultOptions())
    newBank := memory.NewMemoryBankWithStore(newStore, newEngine)
    newSessionMemory := memory.NewSessionMemory(newBank, 10)
    
    agent2, _ := agent.New(agent.Options{
        Model:        model,
        Memory:       newSessionMemory,
        SystemPrompt: "Default prompt",  // 将被覆盖
    })
    
    // 恢复状态
    fmt.Println("\nRestoring agent state...")
    data, _ := os.ReadFile("agent_checkpoint.json")
    err = agent2.Restore(data)
    if err != nil {
        log.Fatal(err)
    }
    fmt.Println("State restored!")
    
    // 验证记忆是否保留
    response, _ := agent2.Generate(ctx, "session-1", "What is my favorite color?")
    fmt.Println("\nAgent:", response)
    // 应该能回忆起 "blue"
}
```

### 场景 5: UTCP 工具调用与 CodeMode

```go
package main

import (
    "context"
    "fmt"
    "log"
    
    "github.com/Protocol-Lattice/go-agent"
    "github.com/Protocol-Lattice/go-agent/src/adk"
    "github.com/Protocol-Lattice/go-agent/src/adk/modules"
    "github.com/Protocol-Lattice/go-agent/src/memory"
    "github.com/Protocol-Lattice/go-agent/src/models"
    "github.com/universal-tool-calling-protocol/go-utcp"
)

func main() {
    ctx := context.Background()
    
    // 1. 创建 UTCP 客户端
    client, err := utcp.NewUTCPClient(ctx, &utcp.UtcpClientConfig{}, nil, nil)
    if err != nil {
        log.Fatal(err)
    }
    
    // 2. 创建并注册专业智能体为 UTCP 工具
    analystModel, _ := models.NewGeminiLLM(ctx, "gemini-2.5-pro", "Analysis:")
    analystMem := memory.NewSessionMemory(
        memory.NewMemoryBankWithStore(memory.NewInMemoryStore()),
        8,
    )
    
    analyst, err := agent.New(agent.Options{
        Model:        analystModel,
        Memory:       analystMem,
        SystemPrompt: "You are a data analyst.",
    })
    if err != nil {
        log.Fatal(err)
    }
    
    // 注册为 UTCP 工具
    err = analyst.RegisterAsUTCPProvider(ctx, client, "local.analyst", "Analyzes data")
    if err != nil {
        log.Fatal(err)
    }
    fmt.Println("✅ Registered 'local.analyst' tool")
    
    // 3. 直接调用 UTCP 工具
    fmt.Println("\n--- Direct Tool Call ---")
    result, err := client.CallTool(ctx, "local.analyst", map[string]any{
        "instruction": "Analyze Q4 sales trends",
    })
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf("Result: %v\n", result)
    
    // 4. 创建带 CodeMode 的编排智能体
    fmt.Println("\n--- CodeMode Orchestrator ---")
    orchestratorModel, _ := models.NewGeminiLLM(ctx, "gemini-2.5-pro", "")
    
    kit, err := adk.New(ctx,
        adk.WithDefaultSystemPrompt("You orchestrate tools via Go code."),
        adk.WithModules(
            modules.NewModelModule("model", func(context.Context) (models.Agent, error) {
                return orchestratorModel, nil
            }),
            modules.InMemoryMemoryModule(100000, memory.AutoEmbedder(), nil),
        ),
        adk.WithCodeModeUtcp(client, orchestratorModel),
    )
    if err != nil {
        log.Fatal(err)
    }
    
    orchestrator, err := kit.BuildAgent(ctx)
    if err != nil {
        log.Fatal(err)
    }
    
    // 5. 使用自然语言编排工作流
    response, err := orchestrator.Generate(ctx, "session-1",
        "Use the analyst to analyze Q4 sales and provide insights")
    if err != nil {
        log.Fatal(err)
    }
    
    fmt.Println("Orchestrator:", response)
}
```

---

## 最佳实践

### 1. 模型选择

#### 选择原则

| 场景 | 推荐模型 | 理由 |
|------|---------|------|
| **生产环境** | Gemini 2.5 Pro / Claude 3 Opus | 性能强、稳定性高 |
| **开发测试** | Gemini 1.5 Flash / Claude Haiku | 成本低、响应快 |
| **本地部署** | Ollama (Llama, Mistral) | 完全私有、无网络依赖 |
| **多模态** | Gemini 2.5 Pro | 原生支持图片/视频 |
| **长上下文** | Claude 3 Opus (200K tokens) | 处理大量文档 |

#### 代码示例

```go
// 生产环境：高性能
model, _ := models.NewGeminiLLM(ctx, "gemini-2.5-pro", "")

// 开发环境：成本优化
model, _ := models.NewGeminiLLM(ctx, "gemini-1.5-flash", "")

// 本地部署：隐私优先
model, _ := models.NewOllamaLLM(ctx, "llama3.1", "http://localhost:11434")

// 添加缓存层（开发/测试）
cachedModel := models.NewCachedModel(model, 1000)
```

### 2. 记忆系统配置

#### 向量存储选择

| 存储类型 | 适用场景 | 特点 |
|---------|---------|------|
| **InMemoryStore** | 开发/测试、小规模应用 | 快速、无需配置 |
| **PostgresStore** | 生产环境、通用场景 | 成熟稳定、SQL 支持 |
| **QdrantStore** | 高性能检索、大规模数据 | 专业向量数据库 |
| **Neo4jStore** | 需要关系图谱 | 支持复杂关系查询 |
| **MongoStore** | 灵活的文档存储 | NoSQL、易扩展 |

#### 配置示例

```go
// 开发环境：内存存储
store := memory.NewInMemoryStore()

// 生产环境：PostgreSQL
store, err := memory.NewPostgresStore(ctx, os.Getenv("DATABASE_URL"))
if err != nil {
    log.Fatal(err)
}

// 高性能：Qdrant
store, err := memory.NewQdrantStore(ctx, "http://localhost:6333", "memories")
if err != nil {
    log.Fatal(err)
}

// 配置引擎选项
opts := memory.DefaultOptions()
opts.HalfLife = 7 * 24 * time.Hour         // 记忆半衰期：7天 这个半衰期是怎么用的？ 它会根据记忆的年龄自动调整重要性评分，较旧的记忆会逐渐变得不重要，更容易被淘汰。
opts.LambdaMMR = 0.5                       // MMR 平衡参数
opts.EnableSummaries = true                // 启用摘要
opts.TTL = 30 * 24 * time.Hour             // 记忆 TTL：30天
opts.MinImportance = 0.3                   // 最低重要性阈值

engine := memory.NewEngine(store, opts)
```

#### 嵌入模型选择

```go
// 自动选择（推荐）这个生产环境不能用自动吧？ 自动选择会导致同一个环境下不同的机器使用不同的嵌入模型，导致记忆不兼容。生产环境建议显式指定嵌入模型。
embedder := memory.AutoEmbedder()

// 显式指定
embedder, _ := memory.NewOpenAIEmbedder(ctx, "text-embedding-ada-002")
embedder, _ := memory.NewFastEmbeed(ctx, "BAAI/bge-small-en-v1.5")

// 开发测试：虚拟嵌入（无需API）
embedder := memory.DummyEmbedder{}
```

### 3. 上下文管理

#### ContextLimit 设置

```go
agent, _ := agent.New(agent.Options{
    Model:        model,
    Memory:       sessionMemory,
    ContextLimit: 8,  // 推荐值
})
```

**推荐配置**：
- **对话型应用**：6-10 条记忆
- **知识问答**：10-15 条记忆
- **长期助手**：15-20 条记忆

**注意**：过多上下文会增加 token 消耗和延迟。

### 4. 工具设计原则

#### 良好的工具设计

```go
type GoodTool struct{}

func (t *GoodTool) Spec() agent.ToolSpec {
    return agent.ToolSpec{
        Name:        "search_documents",  // 清晰的名称
        Description: "Searches for documents matching the query in the knowledge base. Returns top 5 relevant results.", // 详细说明
        InputSchema: map[string]any{
            "type": "object",
            "properties": map[string]any{
                "query": map[string]any{
                    "type":        "string",
                    "description": "Search query in natural language",
                },
                "filters": map[string]any{
                    "type":        "object",
                    "description": "Optional filters (e.g., date range, category)",
                },
            },
            "required": []string{"query"},  // 明确必需参数
        },
        Examples: []map[string]any{  // 提供示例
            {
                "query":   "quantum computing papers",
                "filters": map[string]any{"year": 2024},
            },
        },
    }
}

func (t *GoodTool) Invoke(ctx context.Context, req agent.ToolRequest) (agent.ToolResponse, error) {
    // 1. 参数验证
    query, ok := req.Arguments["query"].(string)
    if !ok || query == "" {
        return agent.ToolResponse{}, fmt.Errorf("query is required")
    }
    
    // 2. 执行逻辑（带超时控制）
    ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
    defer cancel()
    
    results := performSearch(ctx, query)
    
    // 3. 返回结构化结果
    return agent.ToolResponse{
        Content: formatResults(results),
        Metadata: map[string]string{
            "result_count": strconv.Itoa(len(results)),
            "query_time":   "123ms",
        },
    }, nil
}
```

#### 避免的陷阱

❌ **错误示例**：
```go
// 名称模糊
Name: "do_thing"

// 描述不清
Description: "Does something"

// 缺少类型信息
InputSchema: map[string]any{}

// 返回格式不一致
return agent.ToolResponse{Content: randomFormat()}
```

### 5. 错误处理

#### 推荐模式

```go
func robustAgentCall(ctx context.Context, agent *agent.Agent, sessionID, prompt string) (string, error) {
    // 1. 添加超时
    ctx, cancel := context.WithTimeout(ctx, 30*time.Second)
    defer cancel()
    
    // 2. 调用
    response, err := agent.Generate(ctx, sessionID, prompt)
    if err != nil {
        // 3. 错误分类处理
        if ctx.Err() == context.DeadlineExceeded {
            return "", fmt.Errorf("agent timeout: %w", err)
        }
        
        // 检查是否为 API 限流
        if isRateLimitError(err) {
            time.Sleep(2 * time.Second)
            // 重试
            return agent.Generate(context.Background(), sessionID, prompt)
        }
        
        return "", fmt.Errorf("agent error: %w", err)
    }
    
    return response, nil
}

func isRateLimitError(err error) bool {
    // 根据具体 LLM SDK 的错误类型判断
    return strings.Contains(err.Error(), "rate limit") ||
           strings.Contains(err.Error(), "quota exceeded")
}
```

### 6. 性能优化

#### 批量操作

```go
// ❌ 低效：逐条存储
for _, item := range items {
    memory.Store(ctx, sessionID, item, metadata)
}

// ✅ 高效：批量存储（如果存储支持）
memory.StoreBatch(ctx, sessionID, items, metadata)
```

#### 并发控制

```go
import "github.com/Protocol-Lattice/go-agent/src/concurrent"

// 使用工作池并发处理
pool := concurrent.NewWorkerPool(10)  // 10 个并发 worker

var results []string
var mu sync.Mutex

for _, task := range tasks {
    task := task  // 捕获变量
    pool.Submit(func() error {
        result, err := processTask(task)
        if err != nil {
            return err
        }
        
        mu.Lock()
        results = append(results, result)
        mu.Unlock()
        
        return nil
    })
}

if err := pool.Wait(); err != nil {
    log.Printf("Some tasks failed: %v", err)
}
```

#### 缓存策略

```go
// 1. 模型缓存
cachedModel := models.NewCachedModel(baseModel, 500)

// 2. 工具结果缓存（自定义）
type CachedTool struct {
    inner Tool
    cache *cache.LRUCache[string, agent.ToolResponse]
}

func (t *CachedTool) Invoke(ctx context.Context, req agent.ToolRequest) (agent.ToolResponse, error) {
    key := hashArgs(req.Arguments)
    
    if cached, found := t.cache.Get(key); found {
        return cached, nil
    }
    
    resp, err := t.inner.Invoke(ctx, req)
    if err == nil {
        t.cache.Put(key, resp)
    }
    
    return resp, err
}
```

---

## 配置指南

### 环境变量完整列表

```bash
# === LLM API Keys ===
GOOGLE_API_KEY=your-gemini-key
GEMINI_API_KEY=your-gemini-key          # 替代 GOOGLE_API_KEY
ANTHROPIC_API_KEY=your-claude-key
OPENAI_API_KEY=your-openai-key

# === 嵌入模型 ===
ADK_EMBED_PROVIDER=gemini               # gemini|openai|ollama|fastembed

# === 向量存储 ===
DATABASE_URL=postgres://user:pass@localhost:5432/lattice?sslmode=disable
QDRANT_URL=http://localhost:6333
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
MONGODB_URI=mongodb://localhost:27017

# === Ollama 配置 ===
OLLAMA_HOST=http://localhost:11434

# === 日志级别 ===
LOG_LEVEL=info                          # debug|info|warn|error
```

### 配置文件示例

创建 `config.yaml`：

```yaml
agent:
  system_prompt: "You are a helpful AI assistant."
  context_limit: 10
  
model:
  provider: gemini                       # gemini|claude|openai|ollama
  name: gemini-2.5-pro
  temperature: 0.7
  max_tokens: 8192

memory:
  store: postgres                        # inmemory|postgres|qdrant|neo4j|mongo
  context_limit: 10
  half_life: 168h                        # 7 days
  ttl: 720h                              # 30 days
  lambda_mmr: 0.5
  enable_summaries: true

tools:
  - name: search
    enabled: true
  - name: calculator
    enabled: true
```

加载配置：

```go
import (
    "gopkg.in/yaml.v3"
    "os"
)

type Config struct {
    Agent struct {
        SystemPrompt string `yaml:"system_prompt"`
        ContextLimit int    `yaml:"context_limit"`
    } `yaml:"agent"`
    
    Model struct {
        Provider    string  `yaml:"provider"`
        Name        string  `yaml:"name"`
        Temperature float64 `yaml:"temperature"`
        MaxTokens   int     `yaml:"max_tokens"`
    } `yaml:"model"`
    
    Memory struct {
        Store           string        `yaml:"store"`
        ContextLimit    int           `yaml:"context_limit"`
        HalfLife        time.Duration `yaml:"half_life"`
        TTL             time.Duration `yaml:"ttl"`
        LambdaMMR       float64       `yaml:"lambda_mmr"`
        EnableSummaries bool          `yaml:"enable_summaries"`
    } `yaml:"memory"`
}

func loadConfig(path string) (*Config, error) {
    data, err := os.ReadFile(path)
    if err != nil {
        return nil, err
    }
    
    var cfg Config
    if err := yaml.Unmarshal(data, &cfg); err != nil {
        return nil, err
    }
    
    return &cfg, nil
}
```

---

## 故障排查

### 常见问题

#### 1. API Key 错误

**症状**：
```
Error: GOOGLE_API_KEY or GEMINI_API_KEY required
```

**解决**：
```bash
export GOOGLE_API_KEY="your-actual-api-key"
# 或
export GEMINI_API_KEY="your-actual-api-key"
```

#### 2. 记忆检索为空

**症状**：Agent 无法记住之前的对话

**可能原因**：
- Session ID 不一致
- 嵌入模型未配置
- 存储未正确初始化

**检查**：
```go
// 确保使用相同的 Session ID
response1, _ := agent.Generate(ctx, "session-123", "My name is Alice")
response2, _ := agent.Generate(ctx, "session-123", "What is my name?")
// ✅ 相同 Session ID

// 检查嵌入器
embedder := memory.AutoEmbedder()
if embedder == nil {
    log.Fatal("Embedder not configured")
}
```

#### 3. 工具未被调用

**症状**：Agent 返回文本响应而非调用工具

**可能原因**：
- 工具描述不清晰
- LLM 未理解何时使用工具
- 工具名称不明确

**优化**：
```go
// ❌ 模糊
Description: "Does calculations"

// ✅ 清晰
Description: "Performs arithmetic operations (addition, subtraction, multiplication, division). Use this tool when the user asks for mathematical calculations."
```

#### 4. 内存溢出

**症状**：
```
fatal error: runtime: out of memory
```

**解决**：
```go
// 1. 限制上下文数量
ContextLimit: 10  // 不要设置过大

// 2. 定期修剪记忆
go func() {
    ticker := time.NewTicker(1 * time.Hour)
    for range ticker.C {
        engine.Prune(context.Background())
    }
}()

// 3. 使用持久化存储而非内存
store, _ := memory.NewPostgresStore(ctx, os.Getenv("DATABASE_URL"))
```

#### 5. 响应缓慢

**症状**：每次调用需要 10+ 秒

**排查**：
```go
import "time"

start := time.Now()
response, err := agent.Generate(ctx, sessionID, prompt)
elapsed := time.Since(start)
log.Printf("Generate took %v", elapsed)

// 检查各阶段耗时
// - 记忆检索：< 100ms
// - LLM 生成：2-5s
// - 工具执行：取决于工具
```

**优化**：
- 减少检索的记忆数量
- 使用更快的嵌入模型
- 启用缓存
- 使用更快的 LLM（如 Gemini Flash）

---

## 性能调优

### 基准测试

#### 记忆检索性能

```go
func BenchmarkMemoryRetrieve(b *testing.B) {
    ctx := context.Background()
    store := memory.NewInMemoryStore()
    engine := memory.NewEngine(store, memory.DefaultOptions())
    
    // 预填充数据
    for i := 0; i < 1000; i++ {
        engine.Store(ctx, "session-1", fmt.Sprintf("Memory %d", i), nil)
    }
    
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        _, _ = engine.Retrieve(ctx, "session-1", "test query", 10)
    }
}
```

#### LLM 缓存效果

```go
func BenchmarkCachedModel(b *testing.B) {
    ctx := context.Background()
    baseModel, _ := models.NewGeminiLLM(ctx, "gemini-2.5-pro", "")
    cachedModel := models.NewCachedModel(baseModel, 100)
    
    prompt := "What is 2+2?"
    
    b.Run("WithoutCache", func(b *testing.B) {
        for i := 0; i < b.N; i++ {
            baseModel.Generate(ctx, prompt)
        }
    })
    
    b.Run("WithCache", func(b *testing.B) {
        for i := 0; i < b.N; i++ {
            cachedModel.Generate(ctx, prompt)
        }
    })
}
```

### 监控与指标

```go
// 自定义指标收集
type MetricsCollector struct {
    generateCalls   int64
    totalLatency    time.Duration
    toolCalls       int64
    memoryRetrievals int64
}

func (m *MetricsCollector) RecordGenerate(duration time.Duration) {
    atomic.AddInt64(&m.generateCalls, 1)
    // ... 记录延迟
}

// 定期输出指标
go func() {
    ticker := time.NewTicker(1 * time.Minute)
    for range ticker.C {
        log.Printf("Metrics: calls=%d, avg_latency=%v", 
            metrics.generateCalls, 
            metrics.totalLatency / time.Duration(metrics.generateCalls))
    }
}()
```

---

## 示例代码库

完整的示例代码位于 `cmd/example/` 目录：

| 示例 | 文件 | 说明 |
|------|------|------|
| **CodeMode** | `cmd/example/codemode/main.go` | CodeMode 工具编排 |
| **多智能体工作流** | `cmd/example/codemode_utcp_workflow/main.go` | 多步骤协同 |
| **智能体间通信** | `cmd/example/agent_as_tool/main.go` | 层级架构 |
| **状态持久化** | `cmd/example/checkpoint/main.go` | Checkpoint/Restore |
| **UTCP CodeMode** | `cmd/example/agent_as_utcp_codemode/main.go` | 完整 UTCP 集成 |

运行示例：

```bash
# CodeMode 示例
go run cmd/example/codemode/main.go

# Checkpoint 示例
go run cmd/example/checkpoint/main.go

# 多智能体协同
go run cmd/example/codemode_utcp_workflow/main.go
```

---

## 总结

本指南涵盖了 Go-Agent 的：

✅ **快速开始**：从零搭建第一个智能体  
✅ **常见场景**：对话机器人、工具调用、多智能体、状态持久化  
✅ **最佳实践**：模型选择、记忆配置、工具设计、错误处理  
✅ **配置管理**：环境变量、配置文件、参数调优  
✅ **故障排查**：常见问题诊断与解决  
✅ **性能优化**：基准测试、缓存策略、并发控制  

通过遵循这些实践，您可以构建高效、稳定的生产级 AI 智能体应用。
